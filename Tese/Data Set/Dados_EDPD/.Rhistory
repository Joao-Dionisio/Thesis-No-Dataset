sec[[i]] <- as.numeric(sec[[i]], warning=FALSE)
}
results <- min
for(i in 1:length(min)){
a <- deg[[i]] + min[[i]]/60 + sec[[i]]/3600
if (length(a) != 0){
results[[i]] <- a
}
}
fires.tb$lat <- as.numeric(results)
# Lon
fires.tb_coord<-fires.tb
##fires.tb_coord <- na.omit(fires.tb_coord, na.action = "omit")
fires.tb_coord$lon <- gsub( "^00:", "", fires.tb_coord$lon) # Regex expression for "00:" prefix?
fires.tb_coord$lon <- gsub( "''", "", fires.tb_coord$lon)
fires.tb_coord$lon <- gsub("Âº",":", fires.tb_coord$lon) # Some longitudes needed to be cleaned up. They were like 7Âº48'17.506800000004
fires.tb_coord$lon <- gsub("'",":", fires.tb_coord$lon)
fires.tb_coord$lon <- gsub("\"","", fires.tb_coord$lon)
final <- str_split(fires.tb_coord$lon,":")
# Getting the values from each vector
deg <- map(final, 1)
min <- map(final, 2)
sec <- map(final, 3)
min <- str_split(min,"\\.") #Erro    <- min[[5277]]
for (i in 1:length(min)){
#if(grepl('.', min[[i]], fixed = TRUE)){
if(length(min[[i]])==2){
sec[[i]] <- min[[i]][2]
min[[i]] <- min[[i]][1]
}
}
deg <- sapply(deg, as.numeric )
min <- sapply(min, as.numeric )
for (i in 1:length(min)){
sec[[i]] <- as.numeric(sec[[i]], warning=FALSE)
}
results <- min
for(i in 1:length(min)){
# For some reason some values are negative when they souldn't be so we used "abs"
a <- abs(deg[[i]]) + abs(min[[i]]/60) + abs(sec[[i]]/3600)
if (length(a) != 0){
results[[i]] <- a
}
}
fires.tb$lon <- as.numeric(results)
summary(fires.tb$lon)
# -------------------- Running on the test set --------------------
# Lat
fires.tb.test_coord<-fires.tb.test
##fires.tb.test_coord <- na.omit(fires.tb.test_coord, na.action = "omit")
fires.tb.test_coord$lat <- gsub( "^00:", "", fires.tb.test_coord$lat) # Regex expression for "00:" prefix
fires.tb.test_coord$lat <- gsub( "''", "", fires.tb.test_coord$lat)
fires.tb.test_coord$lat <- gsub("Âº",":", fires.tb.test_coord$lat) # Some latitudes needed to be cleaned up. They were like 40Âº14'47.3567999
fires.tb.test_coord$lat <- gsub("'",":", fires.tb.test_coord$lat)
fires.tb.test_coord$lat <- gsub("\"","", fires.tb.test_coord$lat)
final <- str_split(fires.tb.test_coord$lat,":")
# Getting the values from each vector
deg <- map(final, 1)
min <- map(final, 2)
sec <- map(final, 3)
min <- str_split(min,"\\.")
# Running through the "min" values and separating on the cases where the seconds don't exist and are aggregated in min, e.g., "46.212"
for (i in 1:length(min)){
if(length(min[[i]])==2){
sec[[i]] <- min[[i]][2]
min[[i]] <- min[[i]][1]
}
}
deg <- sapply(deg, as.numeric )
min <- sapply(min, as.numeric )
for (i in 1:length(min)){
sec[[i]] <- as.numeric(sec[[i]], warning=FALSE)
}
results <- min
for(i in 1:length(min)){
a <- deg[[i]] + min[[i]]/60 + sec[[i]]/3600
if (length(a) != 0){
results[[i]] <- a
}
}
fires.tb.test$lat <- as.numeric(results)
# Lon
fires.tb.test_coord<-fires.tb.test
##fires.tb.test_coord <- na.omit(fires.tb.test_coord, na.action = "omit")
fires.tb.test_coord$lon <- gsub( "^00:", "", fires.tb.test_coord$lon) # Regex expression for "00:" prefix?
fires.tb.test_coord$lon <- gsub( "''", "", fires.tb.test_coord$lon)
fires.tb.test_coord$lon <- gsub("Âº",":", fires.tb.test_coord$lon) # Some longitudes needed to be cleaned up. They were like 7Âº48'17.506800000004
fires.tb.test_coord$lon <- gsub("'",":", fires.tb.test_coord$lon)
fires.tb.test_coord$lon <- gsub("\"","", fires.tb.test_coord$lon)
final <- str_split(fires.tb.test_coord$lon,":")
# Getting the values from each vector
deg <- map(final, 1)
min <- map(final, 2)
sec <- map(final, 3)
min <- str_split(min,"\\.") #Erro <- 5277
for (i in 1:length(min)){
#if(grepl('.', min[[i]], fixed = TRUE)){
if(length(min[[i]])==2){
sec[[i]] <- min[[i]][2]
min[[i]] <- min[[i]][1]
}
}
deg <- sapply(deg, as.numeric )
min <- sapply(min, as.numeric )
for (i in 1:length(min)){
sec[[i]] <- as.numeric(sec[[i]], warning=FALSE)
}
results <- min
for(i in 1:length(min)){
# For some reason some values are negative when they souldn't be so we used "abs"
a <- abs(deg[[i]]) + abs(min[[i]]/60) + abs(sec[[i]]/3600)
if (length(a) != 0){
results[[i]] <- a
}
}
fires.tb.test$lon <- as.numeric(results)
summary(fires.tb.test$lon)
# Removing values that
fire.tb <- subset(fires.tb, abs(lon) > 6.16 & abs(lon) < 9.55 & lat < 42.16 & lat > 36.9)
#fires.tb.test <- subset(fires.tb.test, abs(lon) > 6.16 & abs(lon) < 9.55 & lat < 42.16 & lat > 36.9)
#introduction to RNOAA package: http://spatialecology.weebly.com/r-code--data/34
library('rnoaa')
library(GEOmap)
library(fields)
require(devtools)
library(lubridate)
library(plyr)
#options(noaakey ="EITlvatVlwpiatCaYGqHZfQfvQNkXONw") # João
options(noaakey ="kfwoUoJphgOtAwxuFuGPNBLXicwpsznE") # Manuel
#To gain access to NCDC CDO Web Services, you must obtain a token using this link and following the directions given. http://www.ncdc.noaa.gov/cdo-web/token
#Get available stations
#station_data <- ghcnd_stations() # Takes a while to run and you can load form the available R object
load("station_data.Rdata")
#define the GPS coordinates of a fire event
df <- data.frame(
id = c("Porto"),
latitude = c(41.755673),
longitude = c(-8.601734),
stringsAsFactors = FALSE
)
#Get nearby stations that can provide the mean average temperature (TAVG)
#nearby_stations <-  meteo_nearby_stations(lat_lon_df = df,
#                                          station_data = station_data, radius = 1000,
#                                          var = c("TAVG"),
#                                          year_min = 2015, year_max = 2015)
#Get TAVG data
##weather_data <- ghcnd_search(nearby_stations[[1]]$id[1], var = c("TAVG") , date_min = "2015-01-01", date_max = "2015-12-31")
#Get nearby stations that can provide the Maximum temperature (TMAX)
nearby_stations <-  meteo_nearby_stations(lat_lon_df = df,
station_data = station_data, radius = 500,
var = c("TMAX"),
year_min = 2015, year_max = 2015)
#Get TMAX data - We ran once and saved the results in "weather_data_Test.RData"
#weather_data_untreated <- ghcnd_search(nearby_stations[[1]]$id[1], var = c("TMAX") , date_min = "2015-01-01", date_max = "2015-12-31")
#for (i in c(2:length(nearby_stations[[1]]$id))){
#  weather_data_temp <- ghcnd_search(nearby_stations[[1]]$id[i], var = c("TMAX") , date_min = "2015-01-01", date_max = "2015-12-31")
#  weather_data_untreated <- bind_rows(weather_data_untreated, weather_data_temp)
#}
#save(weather_data_untreated, file="weather_data_Test.RData")
load("weather_data_Test.RData") #The data needs to be loaded with the same name as it was saved - in our case "weather_data_untreated"
#write.csv(weather_data_untreated, "weather_data.csv")
#weather_data <- read.csv("weather_data.csv", header=TRUE)
#weather_data <- weather_data$tmax
#weather_data_test<-weather_data_untreated$tmax
#weather_data_tb <- tbl_df(weather_data_test)
#weather_data_tb <- select(weather_data_tb, tmax, date)
# Source - https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt
portugal_ids <- unique(weather_data_untreated$id)
station_information <- read.table("station_information - Copy.csv")
station_ids <- gsub(",.*$","",station_information[[1]])
indices <- vector("list", length(portugal_ids))
cur_index <- 1
for(i in c(1:length(station_information[[1]]))){
if (station_ids[[i]] %in% portugal_ids){
indices[[cur_index]] <- station_information[[1]][i]
cur_index <- cur_index + 1
}
}
write.csv(indices, "test.csv") #Manually adapted into "portuguese_stations.csv"
# Pairing every fire with the closest station. Can be sped up if it takes too long (just look at the region/municipality)
relevant_stations <- read.csv("portuguese_stations.csv")
relevant_lat <- relevant_stations[,2]
relevant_lon <- abs(relevant_stations[,3])
fires.tb <- fires.tb %>% mutate(lat=na.mean(lat),lon=na.mean(lon))
fires.tb.test <- fires.tb.test %>% mutate(lat=na.mean(lat),lon=na.mean(lon))
# Commented because it takes a while to run and we saved the results into "fires_with_temp.csv"
temp <- fires.tb
fires.tb[,"closest_station"] <- NA
for (i in c(1:length(fires.tb$lat))){
best_dist <- Inf
for (j in c(1:length(relevant_stations))){
cur_dist <- distm(c(fires.tb$lon[[i]], fires.tb$lat[[i]]), c(relevant_lon[[j]], relevant_lat[[j]]), fun = distHaversine)
if (cur_dist < best_dist){
best_dist <- cur_dist
best_station <- relevant_stations[[1]][j]
}
}
fires.tb$closest_station[[i]] <- best_station
}
write.csv(fires.tb, "fires_with_temp.csv")
fires.tb <- read.csv("fires_with_temp.csv")
nearby_stations_index <- unique(fires.tb$closest_station)
fires.tb <- fires.tb[order(fires.tb$closest_station),]
cur_index <- 1
cur_temp <- ghcnd_search(relevant_stations[[1]][[cur_index]], var = c("TMAX") , date_min = "2015-01-01", date_max = "2015-12-31")
default_temp <- cur_temp[[1]]
for (i in c(1:length(fires.tb$closest_station))){
if(fires.tb$closest_station[[i]] != cur_index){
cur_index <- cur_index + 1
cur_temp <- ghcnd_search(relevant_stations[[1]][[cur_index]], var = c("TMAX") , date_min = "2015-01-01", date_max = "2015-12-31")
}
temp <- cur_temp[[1]]
a <- temp$tmax[temp$date == as.Date(fires.tb$alert_date[[i]])]
if (length(a) > 0){
fires.tb$closest_station[[i]] <- a
} else {
fires.tb$closest_station[[i]] <-  default_temp$tmax[default_temp$date == as.Date(fires.tb$alert_date[[i]])] # Temporarily using Lisbons's station, that has records for every day
}
}
fires.tb <- fires.tb %>% mutate(closest_station=na.mean(closest_station))
colnames(fires.tb)[which(names(fires.tb) == "closest_station")] <- "temp_max"
nas <- filter(fires.tb, is.na(temp_max))
# Commented because it takes a while to run and we saved the results into "fires_with_temp.csv"
fires.tb.test[,"closest_station"] <- NA
for (i in c(1:length(fires.tb.test$lat))){
best_dist <- Inf
for (j in c(1:length(relevant_stations))){
cur_dist <- distm(c(fires.tb.test$lon[[i]], fires.tb.test$lat[[i]]), c(relevant_lon[[j]], relevant_lat[[j]]), fun = distHaversine)
if (cur_dist < best_dist){
best_dist <- cur_dist
best_station <- relevant_stations[[1]][j]
}
}
fires.tb.test$closest_station[[i]] <- best_station
}
nearby_stations_index <- unique(fires.tb.test$closest_station)
fires.tb.test <- fires.tb.test[order(fires.tb.test$closest_station),]
cur_index <- 1
cur_temp <- ghcnd_search(relevant_stations[[1]][[cur_index]], var = c("TMAX") , date_min = "2015-01-01", date_max = "2015-12-31")
default_temp <- cur_temp[[1]]
for (i in c(1:length(fires.tb.test$closest_station))){
if(fires.tb.test$closest_station[[i]] != cur_index){
cur_index <- cur_index + 1
cur_temp <- ghcnd_search(relevant_stations[[1]][[cur_index]], var = c("TMAX") , date_min = "2015-01-01", date_max = "2015-12-31")
}
temp <- cur_temp[[1]]
a <- temp$tmax[temp$date == as.Date(fires.tb.test$alert_date[[i]])]
if (length(a) > 0){
fires.tb.test$closest_station[[i]] <- a
} else {
fires.tb.test$closest_station[[i]] <-  default_temp$tmax[default_temp$date == as.Date(fires.tb$alert_date[[i]])] # Temporarily using Lisbons's station, that has records for every day
}
}
fires.tb.test <- fires.tb.test %>% mutate(closest_station=na.mean(closest_station))
colnames(fires.tb.test)[which(names(fires.tb.test) == "closest_station")] <- "temp_max"
##fires.tb.test <- select(fires.tb.test, -X)
write.csv(fires.tb.test, "fires.test_with_temp.csv")
fires.tb.test <- read.csv("fires.test_with_temp.csv")
# While working on the Bad Regions
fires.tb_reg <- fires.tb
# Imputing the mean on the "lat" and "lon" missing values
fires.tb_reg <- fires.tb_reg %>% mutate(lat=na.mean(lat),lon=na.mean(lon))
problematic <- filter(fires.tb_reg, region=='-' | region=="",)
fires.tb_reg <- filter(fires.tb_reg, region!="", region!="-")
regions <- unique(fires.tb_reg$region) # Excluding "" and "-"
# Find a 'centroid' of each region by calculating the median
medians <- fires.tb_reg %>%
group_by(region) %>%
summarise_at(vars(lat, lon), funs(mean(.)))
# Atribuir a cada entrada que tem como região "-"
# a região cujo centroide está mais perto
for (i in c(1:length(problematic[[1]]))){ #It could have been used any of the columns to find the length
min_dist <- Inf #The distance to the closest Region
for (j in c(1:length(medians[[1]]))){ #It's gonna compare the distance to the centroid of each region
centr_dist <- distm(c(problematic$lat[[i]], problematic$lon[[i]]), c(medians$lat[[j]], medians$lon[[j]]), fun = distHaversine)
if (centr_dist < min_dist){
min_dist <- centr_dist
closest_region <- j
}
}
problematic$region[[i]] <- medians$region[[closest_region]]
##fires.tb_reg$region[[i]] <- medians$region[[closest_region]] #Não posso fazer diretamente porque os indices nao correspondem
}
# Add the entries that had their region changed (from either "-" or "")
fires.tb_reg<-bind_rows(fires.tb_reg,problematic)
fires.tb<-fires.tb_reg
fires.tb.test <- select(fires.tb.test, -firstInterv_date, -alert_source)
fires.tb <- select(fires.tb, -extinction_date, -firstInterv_date,)
n_na(fires.tb.test)
n_na(fires.tb)
fires.tb_old <- fires.tb
fires.tb.test_old <- fires.tb.test
# Kaggle
set.seed(73)
fires.tb_Mean <- fires.tb
fires.tb.test_Mean <- fires.tb.test
fires.tb_Mean <- select(fires.tb_Mean, lat, lon, temp_max, cause_type)
fires.tb.test_Mean <- select(fires.tb.test_Mean, lat, lon, temp_max)
knn.model <- knn3(cause_type ~.,data=fires.tb_Mean,k=7)
knn.preds <- predict(knn.model,newdata=fires.tb.test_Mean,type="class")
# Saving the results in a CSV file
write.csv(knn.preds,"Results.csv")
# Using "Results" because we dont know how to edit knn.preds directly
Results <- read.csv(file="Results.csv")
Results <- select(Results, id = 1, everything())
Results <- select(Results, cause_type = 2, everything())
temp <- Results %>% mutate(id=id+7511)
write.csv(temp,"Results.csv",row.names=FALSE)
# Pairing every fire with the closest station. Can be sped up if it takes too long (just look at the region/municipality)
relevant_stations <- read.csv("portuguese_stations.csv")
relevant_lat <- relevant_stations[,2]
relevant_lon <- abs(relevant_stations[,3])
fires.tb <- fires.tb %>% mutate(lat=na.mean(lat),lon=na.mean(lon))
fires.tb.test <- fires.tb.test %>% mutate(lat=na.mean(lat),lon=na.mean(lon))
# Commented because it takes a while to run and we saved the results into "fires_with_temp.csv"
temp <- fires.tb
fires.tb[,"closest_station"] <- NA
for (i in c(1:length(fires.tb$lat))){
best_dist <- Inf
for (j in c(1:length(relevant_stations))){
cur_dist <- distm(c(fires.tb$lon[[i]], fires.tb$lat[[i]]), c(relevant_lon[[j]], relevant_lat[[j]]), fun = distHaversine)
if (cur_dist < best_dist){
best_dist <- cur_dist
best_station <- relevant_stations[[1]][j]
}
}
fires.tb$closest_station[[i]] <- best_station
}
write.csv(fires.tb, "fires_with_temp.csv")
fires.tb <- read.csv("fires_with_temp.csv")
nearby_stations_index <- unique(fires.tb$closest_station)
fires.tb <- fires.tb[order(fires.tb$closest_station),]
cur_index <- 1
cur_temp <- ghcnd_search(relevant_stations[[1]][[cur_index]], var = c("TMAX") , date_min = "2015-01-01", date_max = "2015-12-31")
default_temp <- cur_temp[[1]]
for (i in c(1:length(fires.tb$closest_station))){
if(fires.tb$closest_station[[i]] != cur_index){
cur_index <- cur_index + 1
cur_temp <- ghcnd_search(relevant_stations[[1]][[cur_index]], var = c("TMAX") , date_min = "2015-01-01", date_max = "2015-12-31")
}
temp <- cur_temp[[1]]
a <- temp$tmax[temp$date == as.Date(fires.tb$alert_date[[i]])]
if (length(a) > 0){
fires.tb$closest_station[[i]] <- a
} else {
fires.tb$closest_station[[i]] <-  default_temp$tmax[default_temp$date == as.Date(fires.tb$alert_date[[i]])] # Temporarily using Lisbons's station, that has records for every day
}
}
fires.tb <- fires.tb %>% mutate(closest_station=na.mean(closest_station))
colnames(fires.tb)[which(names(fires.tb) == "closest_station")] <- "temp_max"
nas <- filter(fires.tb, is.na(temp_max))
# Commented because it takes a while to run and we saved the results into "fires_with_temp.csv"
fires.tb.test[,"closest_station"] <- NA
for (i in c(1:length(fires.tb.test$lat))){
best_dist <- Inf
for (j in c(1:length(relevant_stations))){
cur_dist <- distm(c(fires.tb.test$lon[[i]], fires.tb.test$lat[[i]]), c(relevant_lon[[j]], relevant_lat[[j]]), fun = distHaversine)
if (cur_dist < best_dist){
best_dist <- cur_dist
best_station <- relevant_stations[[1]][j]
}
}
fires.tb.test$closest_station[[i]] <- best_station
}
install.packages("devtools")
install.packages("readxl")
setwd("C:/Users/jdion/OneDrive/Ambiente de Trabalho/Tese/Data Set/Dados_EDPD")
my_data <- read_excel("RARI2020.xlsx")
library("readxl")
my_data <- read_excel("RARI2020.xlsx")
install.packages("summarytools")
library("summarytools")
dfsummary(my_date)
dfsummary(my_data)
dfSummary(my_data)
my_data <- read_excel("RARI2020.xlsx", skip=3)
dfSummary(my_data)
summary(my_data)
library(dplyr)
dga <- my_date %>%
select(SAPID, H2, CH4, C2H6, C2H4, C2H2, CO, CO2, Diag AC)
dga <- my_date %>%
select("SAPID", "H2", "CH4", "C2H6", "C2H4", "C2H2", "CO", "CO2", "Diag AC")
dga <- my_data %>%
select("SAPID", "H2", "CH4", "C2H6", "C2H4", "C2H2", "CO", "CO2", "Diag AC")
dga <- my_data %>%
select("SAP ID", "H2", "CH4", "C2H6", "C2H4", "C2H2", "CO", "CO2", "Diag AC")
dga
dfSummary(dga)
freq(dga$`Diag AC`)
view(dfSummary(dga))
install.packages("DataExplorer")
library(DataExplorer)
introduce(dga)
view(introduce(dga))
view(introduce(dga))
plot_intro(dga)
plot_bar(dga)
plot_bar(dga, by = "Diag AC")
plot_histogram(dga)
typeof(dga$H2)
dga$H2 <- as.numeric(dga$H2)
typeof(dga$H2)
dga$CH4 <- as.numeric(dga$CH4)
dga$C2H6 <- as.numeric(dga$C2H6)
dga$C2H4 <- as.numeric(dga$C2H4)
dga$C2H2 <- as.numeric(dga$C2H2)
dga$CO <- as.numeric(dga$CO)
dga$CO2 <- as.numeric(dga$CO2)
introduce(dga)
plot_intro(dga)
plot_missing(dga)
plot_bar(dga)
plot_histogram(dga)
plot_density(dga)
plot_qq(dga)
plot_correlation(dga)
plot_boxplot(dga, by = "Diag AC")
furanicos <- my_data %>%
select("SAP ID", "2 FAL 2019", "Recomendações")
furanicos$`2 FAL 2019` <- as.numeric(furanicos$`2 FAL 2019`)
introduce(furanicos)
plot_intro(furanicos)
plot_missing(furanicos)
plot_bar(furanicos)
plot_histogram(furanicos)
plot_density(furanicos)
plot_qq(furanicos)
plot_correlation(furanicos)
plot_boxplot(furanicos, by = "Recomendações")
source('C:/Users/jdion/OneDrive/Ambiente de Trabalho/Tese/Data Set/last_ditch_effort.R')
knitr::opts_knit$set(root.dir = "C:/Users/jdion/OneDrive/Ambiente de Trabalho/Tese/Data Set/Dados_EDPD")
library(readxl)
library(summarytools)
library(dplyr)
library(DataExplorer)
my_data <- read_excel("RARI2020.xlsx", skip=3)
my_data <- read_excel("RARI2020.xlsx", skip=3)
furanicos <- my_data %>%
select("SAP ID", "2 FAL 2019", "Recomendações")
furanicos$`2 FAL 2019` <- as.numeric(furanicos$`2 FAL 2019`)
introduce(furanicos)
plot_intro(furanicos)
plot_intro(furanicos)
plot_missing(furanicos)
plot_bar(furanicos)
plot_histogram(furanicos)
plot_density(furanicos)
plot_qq(furanicos)
plot_correlation(furanicos)
plot_boxplot(furanicos, by = "Recomendações")
introduce(furanicos)
plot_intro(furanicos)
plot_missing(furanicos)
plot_missing(furanicos)
plot_bar(furanicos)
plot_histogram(furanicos)
plot_density(furanicos)
plot_qq(furanicos)
plot_correlation(furanicos)
plot_boxplot(furanicos, by = "Recomendações")
dga <- my_data %>%
select("SAP ID", "H2", "CH4", "C2H6", "C2H4", "C2H2", "CO", "CO2", "Diag AC")
dga$H2 <- as.numeric(dga$H2)
dga$CH4 <- as.numeric(dga$CH4)
dga$C2H6 <- as.numeric(dga$C2H6)
dga$C2H4 <- as.numeric(dga$C2H4)
dga$C2H2 <- as.numeric(dga$C2H2)
dga$CO <- as.numeric(dga$CO)
dga$CO2 <- as.numeric(dga$CO2)
introduce(dga)
plot_intro(dga)
library(readxl)
library(readxl)
library(summarytools)
library(dplyr)
library(DataExplorer)
my_data <- read_excel("RARI2020.xlsx", skip=3)
furanicos <- my_data %>%
select("SAP ID", "2 FAL 2019", "Recomendações")
furanicos$`2 FAL 2019` <- as.numeric(furanicos$`2 FAL 2019`)
introduce(furanicos)
plot_intro(furanicos)
plot_missing(furanicos)
plot_bar(furanicos)
plot_histogram(furanicos)
plot_density(furanicos)
plot_qq(furanicos)
plot_correlation(furanicos)
plot_boxplot(furanicos, by = "Recomendações")
dga <- my_data %>%
select("SAP ID", "H2", "CH4", "C2H6", "C2H4", "C2H2", "CO", "CO2", "Diag AC")
dga$H2 <- as.numeric(dga$H2)
dga$CH4 <- as.numeric(dga$CH4)
dga$C2H6 <- as.numeric(dga$C2H6)
dga$C2H4 <- as.numeric(dga$C2H4)
dga$C2H2 <- as.numeric(dga$C2H2)
dga$CO <- as.numeric(dga$CO)
dga$CO2 <- as.numeric(dga$CO2)
introduce(dga)
plot_intro(dga)
plot_missing(dga)
plot_bar(dga)
plot_histogram(dga)
plot_density(dga)
plot_qq(dga)
plot_correlation(dga)
plot_boxplot(dga, by = "Diag AC")
typeof(dga$H2)
dfSummary(dga)
view(dfSummary(dga))
freq(dga$`Diag AC`)
